{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.metrics import sparse_top_k_categorical_accuracy\n",
    "from sklearn.preprocessing import normalize\n",
    "from tensorflow.python.saved_model import loader_impl\n",
    "from tensorflow.python.keras.saving.saved_model import load as saved_model_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "#load models\n",
    "\n",
    "cwd = os.getcwd()+'/final/'\n",
    "ResNet = tf.keras.models.load_model(cwd+'ResNet.h5')\n",
    "MobileNet = tf.keras.models.load_model(cwd+'MobileNet.h5')\n",
    "NASNet = tf.keras.models.load_model(cwd+'NASNet.h5')\n",
    "\n",
    "models = [ResNet, MobileNet, NASNet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_zoom (RandomZoom)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 80)                102480    \n",
      "=================================================================\n",
      "Total params: 2,360,464\n",
      "Trainable params: 102,480\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_1 (Rescaling)      (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_zoom_1 (RandomZoom)   (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50v2 (Functional)      (None, 7, 7, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 80)                163920    \n",
      "=================================================================\n",
      "Total params: 23,728,720\n",
      "Trainable params: 163,920\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_2 (Rescaling)      (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_zoom_2 (RandomZoom)   (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "NASNet (Functional)          (None, 7, 7, 1056)        4269716   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1056)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 80)                84560     \n",
      "=================================================================\n",
      "Total params: 4,354,276\n",
      "Trainable params: 84,560\n",
      "Non-trainable params: 4,269,716\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ResNet.summary()\n",
    "MobileNet.summary()\n",
    "NASNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30612 files belonging to 80 classes.\n",
      "Using 24490 files for training.\n",
      "lables: ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '9']\n"
     ]
    }
   ],
   "source": [
    "# lood data directory to obtain labels\n",
    "train_path = os.getcwd() + '/data/train_set/'+'train/'\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "IMAGE_SHAPE = (img_height, img_width)\n",
    "\n",
    "batch_size = 64\n",
    "seed = 16\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    labels='inferred', \n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "nr_labels = len(class_names)\n",
    "print('lables:', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the classifiers to compute the best average calculation\n",
    "\n",
    "def predict(file, models, test):\n",
    "    img = tf.keras.preprocessing.image.load_img(file, target_size=(img_height, img_width))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) \n",
    "        \n",
    "        \n",
    "    predictions_1 = models[0].predict(img_array)\n",
    "    predictions_2 = models[1].predict(img_array)\n",
    "    predictions_3 = models[2].predict(img_array)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # nomralize\n",
    "    norm_1 = predictions_1[0] / np.linalg.norm(predictions_1[0])\n",
    "    norm_2 = predictions_2[0] / np.linalg.norm(predictions_2[0])\n",
    "    norm_3 = predictions_3[0] / np.linalg.norm(predictions_3[0])\n",
    "    \n",
    "    predictions_4 = norm_1 + norm_2  +  norm_3\n",
    "    \n",
    "    max_1 = np.argmax(norm_1)\n",
    "    max_2 = np.argmax(norm_2)\n",
    "    max_3 = np.argmax(norm_3)\n",
    "    \n",
    "    if test == True:\n",
    "        print('Resnet: label:', class_names[max_1],'          ,with value:' ,norm_1[max_1])\n",
    "        print('MobileNet: label:',class_names[max_2], '       ,with value: ' ,norm_2[max_2])\n",
    "        print('Nasnet: label:',class_names[max_3], '          ,with value: ' ,norm_3[max_3])\n",
    "        print('Combined: label:',class_names[np.argmax(predictions_4)])\n",
    "        \n",
    "    return class_names[np.argmax(predictions_4)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet: label: 3           ,with value: 0.28782058\n",
      "MobileNet: label: 5        ,with value:  0.21792836\n",
      "Nasnet: label: 3           ,with value:  0.21211657\n",
      "Combined: label: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = os.getcwd()+'/data/test_set/test_set/test_9.jpg'\n",
    "\n",
    "predict(test_image, models, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#create submission and predict for eacht test image\n",
    "\n",
    "rootdir =os.getcwd()+'/data/test_set/test_set'\n",
    "\n",
    "header = [\"img_name\", \"label\"]\n",
    "with open('submission_ResNet_MobileNet_AC.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "    filewriter.writerow(header)\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            label = predict(rootdir+'/'+file, models, False)\n",
    "            filewriter.writerow([file, label])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
